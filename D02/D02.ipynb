{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 00 - Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_(x):\n",
    "    if isinstance(x, list):\n",
    "        sig = list()\n",
    "        for item in x:\n",
    "            sig = np.append(sig, 1 / (1 + math.exp(-item)))\n",
    "    else:\n",
    "        sig = 1 / (1 + math.exp(-x))\n",
    "    return(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01798620996209156\n",
      "0.8807970779778823\n",
      "[0.01798621 0.88079708 0.5       ]\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid_(-4))\n",
    "print(sigmoid_(2))\n",
    "print(sigmoid_([-4, 2, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 01 - Logistic Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_(y_true, y_pred, m, eps=1e-15):\n",
    "    log_loss = 0.0\n",
    "    try:\n",
    "        for i in range(len(y_pred)):\n",
    "            log_loss += y_true[i] * math.log(y_pred[i]) + (1 - y_true[i]) * math.log(1 - y_pred[i])\n",
    "        return(-log_loss / len(y_true))\n",
    "    except:\n",
    "        return (-y_true * math.log(y_pred) + (1 - y_true) * math.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12692801104297263\n",
      "-10.100041078711822\n",
      "7.233347032629922\n"
     ]
    }
   ],
   "source": [
    "# Test n.1\n",
    "x = 4\n",
    "y_true = 1\n",
    "theta = 0.5\n",
    "y_pred = sigmoid_(x * theta)\n",
    "m = 1 # length of y_true is 1\n",
    "print(log_loss_(y_true, y_pred, m))\n",
    "# 0.12692801104297152\n",
    "# Test n.2\n",
    "x = [1, 2, 3, 4]\n",
    "y_true = 0\n",
    "theta = [-1.5, 2.3, 1.4, 0.7]\n",
    "x_dot_theta = sum([a*b for a, b in zip(x, theta)])\n",
    "y_pred = sigmoid_(x_dot_theta)\n",
    "m = 1\n",
    "print(log_loss_(y_true, y_pred, m))\n",
    "# 10.100041078687479\n",
    "# Test n.3\n",
    "x_new = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]\n",
    "y_true = [1, 0, 1]\n",
    "theta = [-1.5, 2.3, 1.4, 0.7]\n",
    "x_dot_theta = []\n",
    "for i in range(len(x_new)):\n",
    "    my_sum = 0\n",
    "    for j in range(len(x_new[i])):\n",
    "        my_sum += x_new[i][j] * theta[j]\n",
    "    x_dot_theta.append(my_sum)\n",
    "y_pred = sigmoid_(x_dot_theta)\n",
    "m = len(y_true)\n",
    "print(log_loss_(y_true, y_pred, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02 - Logistic Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(x, y):\n",
    "    dot = 0.0\n",
    "    if not isinstance(x, np.ndarray) or x.size == 0 or x.ndim > 2:\n",
    "        print('Dot Error : x dim')\n",
    "        return None\n",
    "    if not isinstance(y, np.ndarray) or y.size == 0 or y.ndim > 2:\n",
    "        print('Dot Error : y dim')\n",
    "        return None\n",
    "    if x.ndim != y.ndim:\n",
    "        print('Dot Error : incompatible x and y dim')\n",
    "        return None\n",
    "    #x_t = x.reshape(-1, 1)\n",
    "    for elem in range(x.size):\n",
    "        dot += x[elem] * y[elem]\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_gradient_(x, y_true, y_pred):\n",
    "    \n",
    "    grad = np.empty(0)\n",
    "    for item in x:\n",
    "        grad = np.append(grad, (y_pred - y_true) * np.array(v))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83201839 3.49447722]\n",
      "\n",
      "\n",
      "[ 0.99999686 -0.49999843  2.29999277 -1.49999528  3.19998994]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (5,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-371-85b47c167ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mx_new_dot_theta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new_dot_theta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_gradient_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;31m# [0.9999445100449934, 5.999888854245219, 6.999833364290213, 7.999777874335206, 8.999722384380199\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-370-f2699995227d>\u001b[0m in \u001b[0;36mlog_gradient_\u001b[0;34m(x, y_true, y_pred)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (5,) "
     ]
    }
   ],
   "source": [
    "# Test n.1\n",
    "x = [1, 4.2] # 1 represent the intercept\n",
    "y_true = 1\n",
    "theta = [0.5, -0.5]\n",
    "x_dot_theta = sum([a*b for a, b in zip(x, theta)])\n",
    "y_pred = sigmoid_(x_dot_theta)\n",
    "print(log_gradient_(x, y_pred, y_true))\n",
    "# [0.8320183851339245, 3.494477217562483]\n",
    "print(\"\\n\")\n",
    "# Test n.2\n",
    "x = [1, -0.5, 2.3, -1.5, 3.2]\n",
    "y_true = 0\n",
    "theta = [0.5, -0.5, 1.2, -1.2, 2.3]\n",
    "x_dot_theta = sum([a*b for a, b in zip(x, theta)])\n",
    "y_pred = sigmoid_(x_dot_theta)\n",
    "print(log_gradient_(x, y_true, y_pred))\n",
    "# [0.99999685596372, -0.49999842798186, 2.299992768716556, -1.4999952839455801, 3.1999899390839044]\n",
    "print(\"\\n\")\n",
    "\n",
    "# Test n.3\n",
    "x_new = [[1, 2, 3, 4, 5], [1, 6, 7, 8, 9], [1, 10, 11, 12, 13]]\n",
    "# first column of x_new are intercept values initialized to 1\n",
    "y_true = [1, 0, 1]\n",
    "theta = [0.5, -0.5, 1.2, -1.2, 2.3]\n",
    "x_new_dot_theta = []\n",
    "for i in range(len(x_new)):\n",
    "    my_sum = 0\n",
    "    for j in range(len(x_new[i])):\n",
    "        my_sum += x_new[i][j] * theta[j]\n",
    "    x_new_dot_theta.append(my_sum)\n",
    "y_pred = sigmoid_(x_new_dot_theta)\n",
    "print(log_gradient_(x_new, y_true, y_pred))\n",
    "# [0.9999445100449934, 5.999888854245219, 6.999833364290213, 7.999777874335206, 8.999722384380199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
